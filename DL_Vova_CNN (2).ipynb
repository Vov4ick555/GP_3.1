{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Пришло время для дл, пока я копался с ml, мои товарищи по команде уже закочили 2 модели(табнет и простой табнет и простой перцептрон), при условии что нам нужно осмысленное отличие модели я отановлбсь на свёртке.\n",
        "Пред обработаем данные так каки в ML и закодируем целевую переменную лейбл инкодером как это делали в MLP"
      ],
      "metadata": {
        "id": "9Z8V_9s7BDm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rZvtLmHgBCmD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "split_idx = int(0.8 * len(train))\n",
        "test = train.iloc[split_idx:]\n",
        "train = train.iloc[:split_idx]\n",
        "\n",
        "X_train = train.drop('Fertilizer Name', axis=1)\n",
        "y_train = train['Fertilizer Name']\n",
        "\n",
        "X_test = test.drop('Fertilizer Name', axis=1)\n",
        "y_test = test['Fertilizer Name']\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_cols = ['Soil Type', 'Crop Type']\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "X_train_encoded = encoder.fit_transform(X_train[cat_cols]).toarray()\n",
        "feature_names = encoder.get_feature_names_out(cat_cols)\n",
        "X_test_encoded = encoder.transform(X_test[cat_cols]).toarray()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "num_cols = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
        "X_test_scaled = scaler.transform(X_test[num_cols])\n",
        "\n",
        "X_train_processed = np.hstack([X_train_scaled, X_train_encoded])\n",
        "X_test_processed = np.hstack([X_test_scaled, X_test_encoded])\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,memory.total,memory.free,memory.used --format=csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbsYaG_m8zu7",
        "outputId": "a62d80f5-44d2-49cf-97a3-6eda1fed7792"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long).to(device)\n",
        "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long).to(device)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(X_train_tensor))\n",
        "val_size = len(X_train_tensor) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    TensorDataset(X_train_tensor, y_train_tensor),\n",
        "    [train_size, val_size]\n",
        ")\n",
        "\n",
        "batch_size = 128 if device.type == 'cuda' else 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)\n",
        "\n",
        "\n",
        "def calculate_accuracy(loader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_model(loader, model):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "input_size = X_train_processed.shape[1]\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "cnn_model = CNN1D_FertilizerClassifier(input_size, num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "cnn_scheduler = ReduceLROnPlateau(cnn_optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "\n",
        "print(f\"\\nОбучение CNN модели на {device} (7 эпох)...\")\n",
        "best_val_accuracy_cnn = 0\n",
        "\n",
        "for epoch in range(1):\n",
        "    cnn_model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/7', leave=True)\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = cnn_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        cnn_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        cnn_optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=running_loss/(progress_bar.n+1))\n",
        "\n",
        "\n",
        "    train_accuracy = calculate_accuracy(train_loader, cnn_model)\n",
        "    val_accuracy = calculate_accuracy(val_loader, cnn_model)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/7], Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "          f\"Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "    cnn_scheduler.step(val_accuracy)\n",
        "\n",
        "    if val_accuracy > best_val_accuracy_cnn:\n",
        "        best_val_accuracy_cnn = val_accuracy\n",
        "        torch.save(cnn_model.state_dict(), 'best_cnn_model.pth')\n",
        "\n",
        "\n",
        "cnn_model.load_state_dict(torch.load('best_cnn_model.pth'))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "test_labels, test_preds = evaluate_model(test_loader, cnn_model)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "precision = precision_score(test_labels, test_preds, average='weighted')\n",
        "recall = recall_score(test_labels, test_preds, average='weighted')\n",
        "f1 = f1_score(test_labels, test_preds, average='weighted')\n",
        "\n",
        "print(\"\\nМетрики CNN модели после 7 эпох обучения:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-score:  {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjyUGFK37GYx",
        "outputId": "edd6668c-b40a-4666-f375-6294c0835101"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Обучение CNN модели на cpu (7 эпох)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/7: 100%|██████████| 7500/7500 [08:32<00:00, 14.64it/s, loss=1.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/7], Loss: 1.9430, Train Acc: 0.1502, Val Acc: 0.1478\n",
            "\n",
            "Метрики CNN модели после 7 эпох обучения:\n",
            "Accuracy:  0.1483\n",
            "Precision: 0.0866\n",
            "Recall:    0.1483\n",
            "F1-score:  0.0683\n"
          ]
        }
      ]
    }
  ]
}